{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58342a89-48bc-4ffe-896f-c9148629fee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "583132f0-df43-444b-8930-379bdb6805b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "XMem_path = os.path.abspath('./XMem')\n",
    "sys.path.append(XMem_path)\n",
    "# !wget -P ./saves/ https://github.com/hkchengrex/XMem/releases/download/v1.0/XMem.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a30f0a10-f32f-4ecf-bfb9-10b01f7bd9a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from inspect import getsource\n",
    "from pathlib import Path\n",
    "from os import path\n",
    "import re\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "# from torchmetrics.classification import BinaryJaccardIndex\n",
    "# from torchmetrics.classification import Dice\n",
    "from torchmetrics.functional.classification import binary_jaccard_index, multiclass_jaccard_index\n",
    "from torchmetrics.functional import dice\n",
    "\n",
    "# from inference.data.test_datasets import LongTestDataset, DAVISTestDataset, YouTubeVOSTestDataset\n",
    "# from inference.data.mask_mapper import MaskMapper\n",
    "from model.network import XMem\n",
    "\n",
    "from inference.inference_core import InferenceCore\n",
    "from inference.data.mask_mapper import MaskMapper\n",
    "\n",
    "from inference.interact.interactive_utils import image_to_torch, index_numpy_to_one_hot_torch, torch_prob_to_numpy_mask\n",
    "\n",
    "from progressbar import progressbar\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# default configuration\n",
    "config = {\n",
    "    'top_k': 30,\n",
    "    'mem_every': 5,\n",
    "    'deep_update_every': -1,\n",
    "    'enable_long_term': True,\n",
    "    'enable_long_term_count_usage': True,\n",
    "    'num_prototypes': 128,\n",
    "    'min_mid_term_frames': 5,\n",
    "    'max_mid_term_frames': 10,\n",
    "    'max_long_term_elements': 10000,\n",
    "}\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  print('Using GPU')\n",
    "  device = 'cuda'\n",
    "else:\n",
    "  print('CUDA not available. Please connect to a GPU instance if possible.')\n",
    "  device = 'cpu'\n",
    "\n",
    "# network = XMem(config, '../XMem/saves/XMem.pth').eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a73ca69-74b0-4bda-9be7-b86eec6b00be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 23 22:32:35 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.146.02             Driver Version: 535.146.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  | 00000000:01:00.0 Off |                  Off |\n",
      "| 30%   40C    P2              43W / 450W |    723MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14be6ca1-a27e-4750-a54f-ea70c862b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# COLOR = (3, 192, 60)\n",
    "\n",
    "\n",
    "# # Pulmonary Vein\n",
    "# main_folder = Path(\"./data\")\n",
    "# VIDEOS_PATH = main_folder/\"tframes\"\n",
    "# MASKS_PATH = main_folder/\"tmasks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f754443a-ecea-4b31-ba0a-ad178f1dd795",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "COLOR = (3, 192, 60)\n",
    "\n",
    "# processor = InferenceCore(network, config=config)\n",
    "# NUM_OBJECTS = 1 # Binary Segmentation\n",
    "# processor.set_all_labels(range(1, NUM_OBJECTS+1))\n",
    "\n",
    "DATASET_TYPE = \"endo\"\n",
    "main_folder = Path(\"./data\")\n",
    "VIDEOS_PATH = main_folder/\"frames\"\n",
    "MASKS_PATH = main_folder/\"masks\"\n",
    "\n",
    "test_videos = VIDEOS_PATH\n",
    "test_masks = MASKS_PATH/\"all_masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4d0b039-36e8-4128-920e-824bc13c7910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depreciated\n",
    "def binary2color(binary_mask, color):\n",
    "    binary_mask = torch_prob_to_numpy_mask(binary_mask)\n",
    "    pred_mask = np.tile(binary_mask[..., np.newaxis], (1,1,3)) # Make it 3 Channel\n",
    "    mask = np.where(pred_mask == (1,)*3, color, 0).astype('uint8') # Convert Prediction with Color\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f51b28be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_map(pred_mask: np.ndarray, gt_mask: np.ndarray):\n",
    "    # Intersection of pred_mask and gt_mask: True Positive\n",
    "    true_positive = np.bitwise_and(pred_mask, gt_mask)\n",
    "    # Only Pred not GT: False Positive\n",
    "    false_positive = np.bitwise_and(pred_mask, np.bitwise_not(gt_mask))\n",
    "    # Only GT not Pred: False Negative\n",
    "    false_negative = np.bitwise_and(np.bitwise_not(pred_mask), gt_mask)\n",
    "\n",
    "    # Colors\n",
    "    green = (0, 255, 0)\n",
    "    red = (255, 0, 0)\n",
    "    blue = (0, 0, 255)\n",
    "\n",
    "    # Creating Color Map Image\n",
    "    h,w = pred_mask.shape[:2]\n",
    "    color_map = np.zeros((h,w,3), dtype=np.uint8)\n",
    "    color_map[true_positive!=0] = green\n",
    "    color_map[false_positive!=0] = red\n",
    "    color_map[false_negative!=0] = blue\n",
    "\n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f098b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Mask\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth Mask\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Map\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.zeros((10,10), dtype=np.uint8)\n",
    "a[4:8, 4:8] = 1\n",
    "b = np.zeros((10,10), dtype=np.uint8)\n",
    "b[2:6, 2:6] = 1\n",
    "c = color_map(a, b)\n",
    "print(\"Predicted Mask\")\n",
    "plt.imshow(a); plt.show()\n",
    "print(\"Ground Truth Mask\")\n",
    "plt.imshow(b); plt.show()\n",
    "print(\"Color Map\")\n",
    "plt.imshow(c); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6db1b5d5-a31e-4dda-ab95-047d377c83e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames2video(frames_dict, folder_save_path, video_name, FPS=5):\n",
    "    video_path = f'{folder_save_path}/{video_name}_{FPS}FPS.mp4'\n",
    "    print(\"Creating video and saving:\", video_path)\n",
    "    frame = frames_dict[list(frames_dict.keys())[-1]]\n",
    "    size1,size2,_ = frame.shape\n",
    "    out = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'mp4v'), FPS, (size2, size1), True)\n",
    "    # Sorting the frames according to frame number eg: frame_007.png\n",
    "    for _,i in sorted(frames_dict.items(), key=lambda x: x[0]):\n",
    "        out_img = cv2.cvtColor(i, cv2.COLOR_BGR2RGB)\n",
    "        out.write(out_img)\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c07d97b3-45cd-4bd3-b3a9-93d4c20ae362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depreciated: Implemented inside getIoU function\n",
    "def pred2overlay(og_frames, pred_frames):\n",
    "    overlay_dict = {}\n",
    "    for frame_name, frame in og_frames.items():\n",
    "        colored_mask = binary2color(pred_frames[frame_name], (34,139,34)) # forestgreen https://www.rapidtables.com/web/color/green-color.html\n",
    "        overlay = cv2.addWeighted(frame, 1, colored_mask, 0.5, 0)\n",
    "        overlay_dict[frame_name] = overlay\n",
    "    return overlay_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d53a0661-5ef8-46b1-b7f8-0d23b38f64bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIoU(pred_frames, path_dicts, video=True, og_frames = None, save_path=None, num_obj=1):\n",
    "    \n",
    "    IoU = torch.zeros(len(pred_frames), num_obj)\n",
    "    dice_ = torch.zeros(len(pred_frames), num_obj)\n",
    "    overlaid_images = {}\n",
    "    # get the first mask frame from pred_frames dictionary and get its shape\n",
    "    _,h,w = pred_frames[list(pred_frames.keys())[0]].shape # [0]:first key\n",
    "    classes_present = Counter()\n",
    "    classes_predicted = Counter()\n",
    "    for i, (frame_name, mask) in enumerate(tqdm(pred_frames.items())):\n",
    "        np_mask = torch_prob_to_numpy_mask(mask) # predictions probabilities to numpy mask\n",
    "        classes_predicted.update(Counter(np.unique(np_mask)))\n",
    "            \n",
    "        torch_mask = torch.tensor(np_mask).to(device)\n",
    "        \n",
    "        truth_mask = io.imread(path_dicts[frame_name][1]) # 0: frame_path, 1: mask_path\n",
    "        truth_mask[truth_mask == 255] = 1\n",
    "        if np.sum(truth_mask) < (0.01*h*w): # if mask is empty or covers less than 1% of image\n",
    "            continue\n",
    "        classes_present.update(Counter(np.unique(truth_mask)))\n",
    "        \n",
    "        if video:\n",
    "            overlaid_images[frame_name] = cv2.addWeighted(og_frames[frame_name], 1, color_map(np_mask, truth_mask), 0.5, 0)\n",
    "        if save_path:\n",
    "            io.imsave(save_path/frame_name, np_mask, check_contrast=False)\n",
    "\n",
    "        truth_mask = torch.tensor(truth_mask).to(device)\n",
    "\n",
    "        if num_obj > 1:\n",
    "            # Have to give background too as num_classes, and in output ignoring background by doing [1:]\n",
    "            IoU[i] = multiclass_jaccard_index(torch_mask, truth_mask, num_classes=num_obj+1, average=None, ignore_index=0)[1:]\n",
    "            dice_score = dice(torch_mask, truth_mask, num_classes=num_obj+1, average=None, ignore_index=0)[1:]\n",
    "            dice_[i] = dice_score.masked_fill(dice_score.isnan(), 0)\n",
    "        else:\n",
    "            IoU[i] = binary_jaccard_index(torch_mask, truth_mask)\n",
    "            dice_[i] = dice(torch_mask, truth_mask)\n",
    "\n",
    "\n",
    "    print(\"All Present Classes:\", classes_present)\n",
    "    print(\"All Predicted Classes:\", classes_predicted)\n",
    "\n",
    "    meanIoU = IoU.mean(dim=0) # Mean across num of frames\n",
    "    meanDice = dice_.mean(dim=0)\n",
    "    \n",
    "    return meanIoU, IoU, meanDice, dice, overlaid_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62ec5895-4780-4277-b42c-26f2f7f4740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_normalization = transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225]\n",
    "                )\n",
    "\n",
    "def resize_mask(mask, size, num_obj):\n",
    "        mask = mask.unsqueeze(0).unsqueeze(0)\n",
    "        h, w = mask.shape[-2:]\n",
    "        min_hw = min(h, w)\n",
    "        mask = F.interpolate(mask, (int(h/min_hw*size), int(w/min_hw*size)), \n",
    "                    mode='nearest')\n",
    "        mask = mask.squeeze(0,1).long()\n",
    "        return F.one_hot(mask, num_classes=num_obj+1).permute(2,0,1).float()\n",
    "\n",
    "def singleVideoInference(images_paths, first_mask, processor, size = -1, num_obj = 1):\n",
    "    predictions = {}\n",
    "    frames = {}\n",
    "    with torch.cuda.amp.autocast(enabled=True):\n",
    "\n",
    "        # images_paths = sorted(images_paths)\n",
    "\n",
    "        # First Frame\n",
    "        frame = io.imread(images_paths[0])\n",
    "        og_shape = frame.shape[:2]\n",
    "        if size < 0:\n",
    "            im_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                im_normalization,\n",
    "            ])\n",
    "        else:\n",
    "            im_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                im_normalization,\n",
    "                transforms.Resize(size, interpolation=InterpolationMode.BILINEAR, antialias=False),\n",
    "            ])\n",
    "            \n",
    "        frame_torch = im_transform(frame).to(device)\n",
    "        first_mask = first_mask.astype(np.uint8)\n",
    "        if size > 0:\n",
    "            first_mask = torch.tensor(first_mask).to(device)\n",
    "            first_mask = resize_mask(first_mask, size, num_obj)\n",
    "        else:\n",
    "            first_mask = index_numpy_to_one_hot_torch(first_mask, num_obj+1).to(device)\n",
    "        \n",
    "        first_mask = first_mask[1:]    \n",
    "        prediction = processor.step(frame_torch, first_mask)\n",
    "        \n",
    "        for image_path in tqdm(images_paths[1:]):\n",
    "            frame = io.imread(image_path)\n",
    "            # convert numpy array to pytorch tensor format\n",
    "            frame_torch = im_transform(frame).to(device)\n",
    "            \n",
    "            prediction = processor.step(frame_torch)\n",
    "            # Upsample to original size if needed\n",
    "            if size > 0:\n",
    "                prediction = F.interpolate(prediction.unsqueeze(1), og_shape, mode='bilinear', align_corners=False)[:,0]\n",
    "            predictions[image_path.name] = prediction\n",
    "            frames[image_path.name] = frame\n",
    "\n",
    "    return frames, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "add1feb9-c9a4-4082-9972-19ae9c521664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstMaskGT(mask_files):\n",
    "\n",
    "    for idx, mask_path in enumerate(mask_files):        \n",
    "        \n",
    "        mask = io.imread(mask_path)\n",
    "        # All 255 Values replaced with 1, other values remain as it is.\n",
    "        mask = np.where(mask == 255, 1, mask)\n",
    "        h,w = mask.shape\n",
    "        if np.sum(mask) > 0 and ( np.sum(mask) > (0.01*h*w) ): # or can use percentage of image, like > 1%\n",
    "            return mask, idx\n",
    "            \n",
    "    return None, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb4aac47-f043-40c4-a3cc-d53d6139a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doInference(network_path, config, sorted_paths, size = -1, video=False):\n",
    "    overallIoU = []\n",
    "    overallDice = []\n",
    "    for pat_name, sorted_paths_dict in sorted_paths.items():\n",
    "    \n",
    "        # Clearing GPU Cache\n",
    "        torch.cuda.empty_cache()\n",
    "        network = XMem(config, network_path).eval().to(device)\n",
    "        processor = InferenceCore(network, config=config)\n",
    "        NUM_OBJECTS = 11\n",
    "        processor.set_all_labels(range(1, NUM_OBJECTS+1))\n",
    "\n",
    "        image_files = [img_path for img_path, _ in sorted_paths_dict.values()]\n",
    "        mask_files = [mask_path for _, mask_path in sorted_paths_dict.values()]\n",
    "        \n",
    "        # Getting first Ground Truth mask.\n",
    "        mask, start_idx = firstMaskGT(mask_files)\n",
    "        print(\"Mask starting from:\", start_idx)\n",
    "    \n",
    "        print(f\"Running Inference on {pat_name}...\")\n",
    "        frames, predictions = singleVideoInference(image_files[start_idx:], mask,\n",
    "                                                  processor, size = size, num_obj = NUM_OBJECTS)\n",
    "        save_path = None\n",
    "        if video:\n",
    "            save_path = Path(f\"./pred_masks/{pat_name}\")\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            \n",
    "        IoU, _, dice, _, overlaid_images = getIoU(predictions, sorted_paths_dict,\n",
    "                                 video=video, og_frames = frames, save_path=save_path,\n",
    "                                 num_obj = NUM_OBJECTS)\n",
    "        \n",
    "        print(f\"Video \\\"{pat_name}\\\", mean IoU is: {IoU*100}\")\n",
    "        print(f\"Video \\\"{pat_name}\\\", mean dice is: {dice*100}\")\n",
    "\n",
    "        # Convert to Video\n",
    "        if video:\n",
    "            os.makedirs(\"./videos\", exist_ok=True)\n",
    "            frames2video(frames_dict=overlaid_images, folder_save_path = \"./videos\", video_name=pat_name, FPS=5)\n",
    "        \n",
    "        overallIoU.append(IoU)\n",
    "        overallDice.append(dice)\n",
    "        print()\n",
    "\n",
    "        del network, processor\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    print(f\"Average IoU over all videos is: {sum(overallIoU)/len(overallIoU)}.\")\n",
    "    print(f\"Average Dice over all videos is: {sum(overallDice)/len(overallDice)}.\")\n",
    "\n",
    "    return overallIoU, overallDice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d819c288-0395-4886-9ccc-3b1c84ae9207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paths(video_folder_path, mask_folder_path, test_patients=None):\n",
    "    paths = {}\n",
    "    for folder in sorted(mask_folder_path.iterdir()):\n",
    "        pat_name = folder.name if DATASET_TYPE==\"endo\" else folder.name.split('_')[0]\n",
    "        if test_patients and pat_name not in test_patients:\n",
    "            continue\n",
    "        paths[pat_name] = {}\n",
    "        for mask_path in folder.iterdir():\n",
    "            paths[pat_name][mask_path.name] = (video_folder_path/folder.name/mask_path.name, mask_path)\n",
    "    \n",
    "    sorted_paths = {pat: {k:v for k,v in sorted(l.items(), key=lambda x: x[0])} for pat, l in paths.items()}\n",
    "\n",
    "    return sorted_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd5dd2-72b9-4825-8682-647c196be83e",
   "metadata": {},
   "source": [
    "## Check all .pth files and select best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0614489e-50fd-44bc-b469-8a84db5f01f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_folder = \"Jan23_19.31.24_Endo18All_NoAug\" # Weights Folder\n",
    "patient1 = \"p14\" # Test Patient 1\n",
    "patient2 = \"p20\" # Test Patient 2\n",
    "comb = patient1+patient2\n",
    "\n",
    "TEST_PATIENTS = None # set([patient1, patient2])\n",
    "TEST_PATIENTS = set([\"seq_17\", \"seq_18\", \"seq_19\", \"seq_20\", ])\n",
    "# TEST_PATIENTS = set([\"rll-p01\", \"p01\", \"p02\", \"p03\"]) # For RLL PV and LUL PA dataset testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b1671d",
   "metadata": {},
   "source": [
    "### Inference using each `.pth` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5337d6cc-7c64-4b56-a7b1-23f4d78628cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jan23_16.19.01_Endo18Part_RandAffine_250.pth\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:07<00:00, 31.60it/s]\n",
      "100%|██████████| 249/249 [00:01<00:00, 144.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_17\", mean IoU is: tensor([0.7351, 0.5349, 0.5494])\n",
      "Video \"seq_17\", mean dice is: tensor([0.7633, 0.5832, 0.6531])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.46it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 150.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_18\", mean IoU is: tensor([0.8658, 0.7233, 0.4705])\n",
      "Video \"seq_18\", mean dice is: tensor([0.8848, 0.6670, 0.5662])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 31.97it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 146.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_19\", mean IoU is: tensor([0.8617, 0.5912, 0.7294])\n",
      "Video \"seq_19\", mean dice is: tensor([0.8759, 0.6187, 0.7747])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 95\n",
      "Running Inference on seq_20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:04<00:00, 33.10it/s]\n",
      "100%|██████████| 153/153 [00:00<00:00, 169.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_20\", mean IoU is: tensor([0.4277, 0.4021, 0.2804])\n",
      "Video \"seq_20\", mean dice is: tensor([0.4604, 0.4192, 0.3642])\n",
      "\n",
      "Average IoU over all videos is: tensor([0.7226, 0.5629, 0.5074]).\n",
      "Average Dice over all videos is: tensor([0.7461, 0.5720, 0.5895]).\n",
      "****************************************************************************************************\n",
      "Jan23_16.19.01_Endo18Part_RandAffine_500.pth\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:07<00:00, 32.54it/s]\n",
      "100%|██████████| 249/249 [00:01<00:00, 151.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_17\", mean IoU is: tensor([0.7750, 0.5356, 0.4658])\n",
      "Video \"seq_17\", mean dice is: tensor([0.7782, 0.5746, 0.5602])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.66it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 149.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_18\", mean IoU is: tensor([0.8835, 0.6564, 0.4770])\n",
      "Video \"seq_18\", mean dice is: tensor([0.8815, 0.6395, 0.5591])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.00it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 151.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_19\", mean IoU is: tensor([0.8852, 0.6205, 0.7027])\n",
      "Video \"seq_19\", mean dice is: tensor([0.8832, 0.6504, 0.7666])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 95\n",
      "Running Inference on seq_20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:04<00:00, 33.10it/s]\n",
      "100%|██████████| 153/153 [00:00<00:00, 165.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_20\", mean IoU is: tensor([0.4923, 0.4299, 0.2583])\n",
      "Video \"seq_20\", mean dice is: tensor([0.4567, 0.4198, 0.3434])\n",
      "\n",
      "Average IoU over all videos is: tensor([0.7590, 0.5606, 0.4760]).\n",
      "Average Dice over all videos is: tensor([0.7499, 0.5711, 0.5573]).\n",
      "****************************************************************************************************\n",
      "Jan23_16.19.01_Endo18Part_RandAffine_750.pth\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:07<00:00, 32.58it/s]\n",
      "100%|██████████| 249/249 [00:01<00:00, 152.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_17\", mean IoU is: tensor([0.7583, 0.5136, 0.4503])\n",
      "Video \"seq_17\", mean dice is: tensor([0.7307, 0.5481, 0.5391])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.71it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 150.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_18\", mean IoU is: tensor([0.8816, 0.5889, 0.4438])\n",
      "Video \"seq_18\", mean dice is: tensor([0.8309, 0.5555, 0.5317])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.04it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 152.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_19\", mean IoU is: tensor([0.8777, 0.5953, 0.6604])\n",
      "Video \"seq_19\", mean dice is: tensor([0.8298, 0.5939, 0.7232])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 95\n",
      "Running Inference on seq_20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:04<00:00, 32.99it/s]\n",
      "100%|██████████| 153/153 [00:00<00:00, 166.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_20\", mean IoU is: tensor([0.4294, 0.3747, 0.2312])\n",
      "Video \"seq_20\", mean dice is: tensor([0.3525, 0.3607, 0.3154])\n",
      "\n",
      "Average IoU over all videos is: tensor([0.7368, 0.5181, 0.4464]).\n",
      "Average Dice over all videos is: tensor([0.6860, 0.5146, 0.5273]).\n",
      "****************************************************************************************************\n",
      "Jan23_16.19.01_Endo18Part_RandAffine_1000.pth\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:07<00:00, 32.37it/s]\n",
      "100%|██████████| 249/249 [00:01<00:00, 150.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_17\", mean IoU is: tensor([0.7490, 0.4589, 0.3567])\n",
      "Video \"seq_17\", mean dice is: tensor([0.7442, 0.4376, 0.4508])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.54it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 153.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_18\", mean IoU is: tensor([0.8659, 0.5184, 0.4107])\n",
      "Video \"seq_18\", mean dice is: tensor([0.8713, 0.5013, 0.4878])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.13it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 155.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_19\", mean IoU is: tensor([0.8602, 0.5709, 0.6238])\n",
      "Video \"seq_19\", mean dice is: tensor([0.8474, 0.5587, 0.6847])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 95\n",
      "Running Inference on seq_20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:04<00:00, 32.93it/s]\n",
      "100%|██████████| 153/153 [00:00<00:00, 169.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_20\", mean IoU is: tensor([0.4610, 0.3807, 0.2197])\n",
      "Video \"seq_20\", mean dice is: tensor([0.3828, 0.3581, 0.3023])\n",
      "\n",
      "Average IoU over all videos is: tensor([0.7340, 0.4822, 0.4027]).\n",
      "Average Dice over all videos is: tensor([0.7114, 0.4639, 0.4814]).\n",
      "****************************************************************************************************\n",
      "Jan23_16.19.01_Endo18Part_RandAffine_1250.pth\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:07<00:00, 32.51it/s]\n",
      "100%|██████████| 249/249 [00:01<00:00, 150.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_17\", mean IoU is: tensor([0.6507, 0.2880, 0.4536])\n",
      "Video \"seq_17\", mean dice is: tensor([0.7074, 0.3782, 0.5370])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.61it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 150.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_18\", mean IoU is: tensor([0.7891, 0.3213, 0.3958])\n",
      "Video \"seq_18\", mean dice is: tensor([0.8410, 0.4071, 0.5006])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.04it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 153.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_19\", mean IoU is: tensor([0.7860, 0.3318, 0.5445])\n",
      "Video \"seq_19\", mean dice is: tensor([0.8246, 0.4307, 0.6546])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 95\n",
      "Running Inference on seq_20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:04<00:00, 33.10it/s]\n",
      "100%|██████████| 153/153 [00:00<00:00, 172.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_20\", mean IoU is: tensor([0.2266, 0.2507, 0.1581])\n",
      "Video \"seq_20\", mean dice is: tensor([0.2435, 0.3001, 0.2324])\n",
      "\n",
      "Average IoU over all videos is: tensor([0.6131, 0.2980, 0.3880]).\n",
      "Average Dice over all videos is: tensor([0.6541, 0.3791, 0.4812]).\n",
      "****************************************************************************************************\n",
      "Jan23_16.19.01_Endo18Part_RandAffine_1500.pth\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:07<00:00, 32.58it/s]\n",
      "100%|██████████| 249/249 [00:01<00:00, 150.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_17\", mean IoU is: tensor([0.6408, 0.4270, 0.5622])\n",
      "Video \"seq_17\", mean dice is: tensor([0.6801, 0.4740, 0.6330])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.69it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 151.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_18\", mean IoU is: tensor([0.7712, 0.4349, 0.4666])\n",
      "Video \"seq_18\", mean dice is: tensor([0.8145, 0.4761, 0.5615])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 31.97it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 152.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_19\", mean IoU is: tensor([0.8285, 0.5034, 0.6434])\n",
      "Video \"seq_19\", mean dice is: tensor([0.8245, 0.5611, 0.7049])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 95\n",
      "Running Inference on seq_20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:04<00:00, 33.15it/s]\n",
      "100%|██████████| 153/153 [00:00<00:00, 170.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_20\", mean IoU is: tensor([0.3054, 0.2591, 0.2530])\n",
      "Video \"seq_20\", mean dice is: tensor([0.3080, 0.2963, 0.3344])\n",
      "\n",
      "Average IoU over all videos is: tensor([0.6365, 0.4061, 0.4813]).\n",
      "Average Dice over all videos is: tensor([0.6568, 0.4519, 0.5585]).\n",
      "****************************************************************************************************\n",
      "Jan23_16.19.01_Endo18Part_RandAffine_1750.pth\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:07<00:00, 32.32it/s]\n",
      "100%|██████████| 249/249 [00:01<00:00, 148.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_17\", mean IoU is: tensor([0.6727, 0.4892, 0.5177])\n",
      "Video \"seq_17\", mean dice is: tensor([0.7145, 0.5272, 0.5854])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.70it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 153.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_18\", mean IoU is: tensor([0.8264, 0.5189, 0.4543])\n",
      "Video \"seq_18\", mean dice is: tensor([0.8609, 0.5306, 0.5415])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.16it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 148.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_19\", mean IoU is: tensor([0.8383, 0.5393, 0.6510])\n",
      "Video \"seq_19\", mean dice is: tensor([0.8453, 0.5877, 0.7075])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 95\n",
      "Running Inference on seq_20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:04<00:00, 33.11it/s]\n",
      "100%|██████████| 153/153 [00:00<00:00, 168.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_20\", mean IoU is: tensor([0.3395, 0.3271, 0.2197])\n",
      "Video \"seq_20\", mean dice is: tensor([0.3400, 0.3417, 0.2996])\n",
      "\n",
      "Average IoU over all videos is: tensor([0.6692, 0.4686, 0.4607]).\n",
      "Average Dice over all videos is: tensor([0.6902, 0.4968, 0.5335]).\n",
      "****************************************************************************************************\n",
      "Jan23_16.19.01_Endo18Part_RandAffine_2000.pth\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:07<00:00, 32.48it/s]\n",
      "100%|██████████| 249/249 [00:01<00:00, 149.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_17\", mean IoU is: tensor([0.7046, 0.4827, 0.5500])\n",
      "Video \"seq_17\", mean dice is: tensor([0.7239, 0.5252, 0.5885])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.69it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 150.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_18\", mean IoU is: tensor([0.8225, 0.4722, 0.4421])\n",
      "Video \"seq_18\", mean dice is: tensor([0.8515, 0.5138, 0.5246])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.16it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 150.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_19\", mean IoU is: tensor([0.8431, 0.5569, 0.6492])\n",
      "Video \"seq_19\", mean dice is: tensor([0.8403, 0.5859, 0.6930])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 95\n",
      "Running Inference on seq_20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:04<00:00, 32.94it/s]\n",
      "100%|██████████| 153/153 [00:00<00:00, 168.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_20\", mean IoU is: tensor([0.3526, 0.3302, 0.2575])\n",
      "Video \"seq_20\", mean dice is: tensor([0.3478, 0.3642, 0.3350])\n",
      "\n",
      "Average IoU over all videos is: tensor([0.6807, 0.4605, 0.4747]).\n",
      "Average Dice over all videos is: tensor([0.6909, 0.4973, 0.5353]).\n",
      "****************************************************************************************************\n",
      "Jan23_16.19.01_Endo18Part_RandAffine_2250.pth\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:07<00:00, 32.60it/s]\n",
      "100%|██████████| 249/249 [00:01<00:00, 151.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_17\", mean IoU is: tensor([0.7007, 0.5377, 0.5922])\n",
      "Video \"seq_17\", mean dice is: tensor([0.7261, 0.5326, 0.5967])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.63it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 147.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_18\", mean IoU is: tensor([0.8450, 0.5023, 0.4622])\n",
      "Video \"seq_18\", mean dice is: tensor([0.8602, 0.5154, 0.5463])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.05it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 153.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_19\", mean IoU is: tensor([0.8398, 0.5547, 0.6788])\n",
      "Video \"seq_19\", mean dice is: tensor([0.8467, 0.5618, 0.7061])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 95\n",
      "Running Inference on seq_20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:04<00:00, 32.89it/s]\n",
      "100%|██████████| 153/153 [00:00<00:00, 170.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_20\", mean IoU is: tensor([0.3729, 0.3065, 0.2722])\n",
      "Video \"seq_20\", mean dice is: tensor([0.3754, 0.3472, 0.3564])\n",
      "\n",
      "Average IoU over all videos is: tensor([0.6896, 0.4753, 0.5013]).\n",
      "Average Dice over all videos is: tensor([0.7021, 0.4892, 0.5514]).\n",
      "****************************************************************************************************\n",
      "Jan23_16.19.01_Endo18Part_RandAffine_2500.pth\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:07<00:00, 32.57it/s]\n",
      "100%|██████████| 249/249 [00:01<00:00, 148.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_17\", mean IoU is: tensor([0.7140, 0.4962, 0.6378])\n",
      "Video \"seq_17\", mean dice is: tensor([0.7410, 0.5345, 0.6570])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.66it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 150.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_18\", mean IoU is: tensor([0.8637, 0.5278, 0.4707])\n",
      "Video \"seq_18\", mean dice is: tensor([0.8725, 0.5481, 0.5473])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 31.97it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 150.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_19\", mean IoU is: tensor([0.8710, 0.5734, 0.7000])\n",
      "Video \"seq_19\", mean dice is: tensor([0.8520, 0.5934, 0.7228])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 95\n",
      "Running Inference on seq_20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:04<00:00, 33.14it/s]\n",
      "100%|██████████| 153/153 [00:00<00:00, 170.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_20\", mean IoU is: tensor([0.3811, 0.3413, 0.2782])\n",
      "Video \"seq_20\", mean dice is: tensor([0.3749, 0.3799, 0.3612])\n",
      "\n",
      "Average IoU over all videos is: tensor([0.7074, 0.4847, 0.5217]).\n",
      "Average Dice over all videos is: tensor([0.7101, 0.5140, 0.5721]).\n",
      "****************************************************************************************************\n",
      "Jan23_16.19.01_Endo18Part_RandAffine_2750.pth\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:07<00:00, 32.62it/s]\n",
      "100%|██████████| 249/249 [00:01<00:00, 151.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_17\", mean IoU is: tensor([0.6827, 0.4297, 0.5990])\n",
      "Video \"seq_17\", mean dice is: tensor([0.7199, 0.4935, 0.6271])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.64it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 150.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_18\", mean IoU is: tensor([0.8315, 0.5044, 0.4523])\n",
      "Video \"seq_18\", mean dice is: tensor([0.8646, 0.5424, 0.5334])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.07it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 147.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_19\", mean IoU is: tensor([0.8599, 0.5489, 0.6690])\n",
      "Video \"seq_19\", mean dice is: tensor([0.8544, 0.5926, 0.7040])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 95\n",
      "Running Inference on seq_20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:04<00:00, 32.94it/s]\n",
      "100%|██████████| 153/153 [00:00<00:00, 169.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_20\", mean IoU is: tensor([0.3642, 0.3098, 0.2480])\n",
      "Video \"seq_20\", mean dice is: tensor([0.3759, 0.3617, 0.3307])\n",
      "\n",
      "Average IoU over all videos is: tensor([0.6846, 0.4482, 0.4921]).\n",
      "Average Dice over all videos is: tensor([0.7037, 0.4976, 0.5488]).\n",
      "****************************************************************************************************\n",
      "Jan23_16.19.01_Endo18Part_RandAffine_3000.pth\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:07<00:00, 32.36it/s]\n",
      "100%|██████████| 249/249 [00:01<00:00, 148.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_17\", mean IoU is: tensor([0.6853, 0.4232, 0.5881])\n",
      "Video \"seq_17\", mean dice is: tensor([0.7198, 0.4847, 0.6270])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.57it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 151.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_18\", mean IoU is: tensor([0.8367, 0.4529, 0.4389])\n",
      "Video \"seq_18\", mean dice is: tensor([0.8548, 0.4930, 0.5234])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.02it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 151.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_19\", mean IoU is: tensor([0.8379, 0.5271, 0.6462])\n",
      "Video \"seq_19\", mean dice is: tensor([0.8379, 0.5810, 0.6941])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 95\n",
      "Running Inference on seq_20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:04<00:00, 33.01it/s]\n",
      "100%|██████████| 153/153 [00:00<00:00, 167.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_20\", mean IoU is: tensor([0.3487, 0.3013, 0.2049])\n",
      "Video \"seq_20\", mean dice is: tensor([0.3538, 0.3430, 0.2859])\n",
      "\n",
      "Average IoU over all videos is: tensor([0.6772, 0.4261, 0.4695]).\n",
      "Average Dice over all videos is: tensor([0.6916, 0.4754, 0.5326]).\n",
      "****************************************************************************************************\n",
      "Jan23_16.19.01_Endo18Part_RandAffine_3250.pth\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:07<00:00, 32.70it/s]\n",
      "100%|██████████| 249/249 [00:01<00:00, 149.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_17\", mean IoU is: tensor([0.6639, 0.4684, 0.5991])\n",
      "Video \"seq_17\", mean dice is: tensor([0.7078, 0.5133, 0.6372])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.57it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 151.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_18\", mean IoU is: tensor([0.8219, 0.4974, 0.4459])\n",
      "Video \"seq_18\", mean dice is: tensor([0.8491, 0.5147, 0.5295])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 31.93it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 156.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_19\", mean IoU is: tensor([0.8247, 0.5615, 0.6715])\n",
      "Video \"seq_19\", mean dice is: tensor([0.8343, 0.5963, 0.7122])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 95\n",
      "Running Inference on seq_20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:04<00:00, 33.01it/s]\n",
      "100%|██████████| 153/153 [00:00<00:00, 169.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_20\", mean IoU is: tensor([0.3068, 0.3198, 0.2176])\n",
      "Video \"seq_20\", mean dice is: tensor([0.3261, 0.3643, 0.3014])\n",
      "\n",
      "Average IoU over all videos is: tensor([0.6543, 0.4618, 0.4835]).\n",
      "Average Dice over all videos is: tensor([0.6793, 0.4972, 0.5451]).\n",
      "****************************************************************************************************\n",
      "Jan23_16.19.01_Endo18Part_RandAffine_3500.pth\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:07<00:00, 32.55it/s]\n",
      "100%|██████████| 249/249 [00:01<00:00, 150.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_17\", mean IoU is: tensor([0.6823, 0.4716, 0.6032])\n",
      "Video \"seq_17\", mean dice is: tensor([0.7204, 0.5170, 0.6387])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.57it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 150.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_18\", mean IoU is: tensor([0.8471, 0.4997, 0.4486])\n",
      "Video \"seq_18\", mean dice is: tensor([0.8617, 0.5185, 0.5323])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.09it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 148.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_19\", mean IoU is: tensor([0.8438, 0.5628, 0.6750])\n",
      "Video \"seq_19\", mean dice is: tensor([0.8456, 0.6006, 0.7145])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 95\n",
      "Running Inference on seq_20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:04<00:00, 32.98it/s]\n",
      "100%|██████████| 153/153 [00:00<00:00, 172.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_20\", mean IoU is: tensor([0.3201, 0.3204, 0.2237])\n",
      "Video \"seq_20\", mean dice is: tensor([0.3352, 0.3648, 0.3076])\n",
      "\n",
      "Average IoU over all videos is: tensor([0.6733, 0.4636, 0.4876]).\n",
      "Average Dice over all videos is: tensor([0.6907, 0.5002, 0.5483]).\n",
      "****************************************************************************************************\n",
      "Jan23_16.19.01_Endo18Part_RandAffine_3750.pth\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:07<00:00, 32.58it/s]\n",
      "100%|██████████| 249/249 [00:01<00:00, 148.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_17\", mean IoU is: tensor([0.6725, 0.4466, 0.5560])\n",
      "Video \"seq_17\", mean dice is: tensor([0.7144, 0.4972, 0.5968])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.58it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 147.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_18\", mean IoU is: tensor([0.8284, 0.4921, 0.4309])\n",
      "Video \"seq_18\", mean dice is: tensor([0.8556, 0.5141, 0.5181])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.24it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 146.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_19\", mean IoU is: tensor([0.8295, 0.5486, 0.6545])\n",
      "Video \"seq_19\", mean dice is: tensor([0.8444, 0.5939, 0.7066])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 95\n",
      "Running Inference on seq_20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:04<00:00, 32.95it/s]\n",
      "100%|██████████| 153/153 [00:00<00:00, 169.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_20\", mean IoU is: tensor([0.3131, 0.3100, 0.1985])\n",
      "Video \"seq_20\", mean dice is: tensor([0.3330, 0.3556, 0.2793])\n",
      "\n",
      "Average IoU over all videos is: tensor([0.6609, 0.4493, 0.4600]).\n",
      "Average Dice over all videos is: tensor([0.6869, 0.4902, 0.5252]).\n",
      "****************************************************************************************************\n",
      "Jan23_16.19.01_Endo18Part_RandAffine_4000.pth\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:07<00:00, 32.61it/s]\n",
      "100%|██████████| 249/249 [00:01<00:00, 150.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_17\", mean IoU is: tensor([0.6761, 0.4371, 0.5737])\n",
      "Video \"seq_17\", mean dice is: tensor([0.7097, 0.4909, 0.6024])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.86it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 152.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_18\", mean IoU is: tensor([0.8315, 0.5013, 0.4446])\n",
      "Video \"seq_18\", mean dice is: tensor([0.8463, 0.5132, 0.5252])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.24it/s]\n",
      "100%|██████████| 248/248 [00:01<00:00, 153.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_19\", mean IoU is: tensor([0.8322, 0.5526, 0.6604])\n",
      "Video \"seq_19\", mean dice is: tensor([0.8337, 0.5909, 0.7024])\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 95\n",
      "Running Inference on seq_20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:04<00:00, 33.30it/s]\n",
      "100%|██████████| 153/153 [00:00<00:00, 163.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_20\", mean IoU is: tensor([0.3139, 0.3112, 0.2202])\n",
      "Video \"seq_20\", mean dice is: tensor([0.3320, 0.3585, 0.3040])\n",
      "\n",
      "Average IoU over all videos is: tensor([0.6634, 0.4505, 0.4747]).\n",
      "Average Dice over all videos is: tensor([0.6804, 0.4884, 0.5335]).\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "paths = []\n",
    "for network_path in Path(f\"./saves/{saved_folder}\").iterdir():\n",
    "    if 'checkpoint' in network_path.name or '.pth' not in network_path.name:\n",
    "        continue\n",
    "    paths.append(network_path)\n",
    "\n",
    "sorted_paths = generate_paths(test_videos, test_masks, test_patients = TEST_PATIENTS)\n",
    "IoUs = {}\n",
    "for network_path in sorted(paths, key = lambda x: int(x.name.split('_')[-1].split('.')[0])):\n",
    "    print(network_path.name)\n",
    "    overallIoU, overallDice = doInference(network_path, config, sorted_paths, size = 384)\n",
    "    IoUs[network_path.name] = sum(overallIoU)/len(overallIoU)\n",
    "    print('*'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d99f4e9f-47a1-46a8-b34b-0ace508405de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jan23_16.19.01_Endo18Part_RandAffine_500.pth',\n",
       "  tensor([0.7590, 0.5606, 0.4760])),\n",
       " ('Jan23_16.19.01_Endo18Part_RandAffine_250.pth',\n",
       "  tensor([0.7226, 0.5629, 0.5074])),\n",
       " ('Jan23_16.19.01_Endo18Part_RandAffine_2500.pth',\n",
       "  tensor([0.7074, 0.4847, 0.5217])),\n",
       " ('Jan23_16.19.01_Endo18Part_RandAffine_750.pth',\n",
       "  tensor([0.7368, 0.5181, 0.4464])),\n",
       " ('Jan23_16.19.01_Endo18Part_RandAffine_2250.pth',\n",
       "  tensor([0.6896, 0.4753, 0.5013])),\n",
       " ('Jan23_16.19.01_Endo18Part_RandAffine_2750.pth',\n",
       "  tensor([0.6846, 0.4482, 0.4921])),\n",
       " ('Jan23_16.19.01_Endo18Part_RandAffine_3500.pth',\n",
       "  tensor([0.6733, 0.4636, 0.4876]))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print in Decreasing Order the IoU\n",
    "sorted_path_iou = sorted(IoUs.items(), key=lambda x: x[1].mean(), reverse=True)\n",
    "sorted_path_iou[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "694ecee0-ee49-4268-8f45-a3ab3159936e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All .pth files Inference Completed\n"
     ]
    }
   ],
   "source": [
    "print(\"All .pth files Inference Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47fb051b-6baa-4dd2-85ad-b448f8aad9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./saves/XMem_Endo18Part_RandAffine.pth'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shutil import copy2\n",
    "# Rename and Copy the best model to `saves`\n",
    "to_save_path = f\"./saves/XMem_Endo18Part_RandAffine.pth\"\n",
    "copy2(f\"./saves/{saved_folder}/{sorted_path_iou[0][0]}\", to_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "110d609d-e86a-4b0d-85af-68ebec89928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rename and Copy the Tensorboard Logs to `saves`\n",
    "# for tensorboard_path in Path(f\"./saves/{saved_folder}\").iterdir():\n",
    "#     if \"events.out\" not in tensorboard_path.name:\n",
    "#         continue\n",
    "#     copy2(tensorboard_path, f\"./saves/events.out.tfevents.All-{comb}\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08b1fe88-d4a4-4aa0-9f22-75d34bccdbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: saves/XMem_Endo18Part_RandAffine.pth to s3://endovis/weights/Endo18Part/XMem_Endo18Part_RandAffine.pth\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./saves/XMem_Endo18Part_RandAffine.pth s3://endovis/weights/Endo18Part/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6caa7bfc-9ef4-41f9-ae8e-1996ee951a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:07<00:00, 32.69it/s]\n",
      "100%|██████████| 249/249 [00:06<00:00, 37.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_17\", mean IoU is: tensor([0.7750, 0.5356, 0.4658])\n",
      "Video \"seq_17\", mean dice is: tensor([0.7782, 0.5746, 0.5602])\n",
      "Creating video and saving: ./videos/seq_17_5FPS.mp4\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.42it/s]\n",
      "100%|██████████| 248/248 [00:06<00:00, 38.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_18\", mean IoU is: tensor([0.8835, 0.6564, 0.4770])\n",
      "Video \"seq_18\", mean dice is: tensor([0.8815, 0.6395, 0.5591])\n",
      "Creating video and saving: ./videos/seq_18_5FPS.mp4\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:07<00:00, 32.34it/s]\n",
      "100%|██████████| 248/248 [00:06<00:00, 40.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_19\", mean IoU is: tensor([0.8852, 0.6205, 0.7027])\n",
      "Video \"seq_19\", mean dice is: tensor([0.8832, 0.6504, 0.7666])\n",
      "Creating video and saving: ./videos/seq_19_5FPS.mp4\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 95\n",
      "Running Inference on seq_20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:04<00:00, 33.24it/s]\n",
      "100%|██████████| 153/153 [00:03<00:00, 48.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"seq_20\", mean IoU is: tensor([0.4923, 0.4299, 0.2583])\n",
      "Video \"seq_20\", mean dice is: tensor([0.4567, 0.4198, 0.3434])\n",
      "Creating video and saving: ./videos/seq_20_5FPS.mp4\n",
      "\n",
      "Average IoU over all videos is: tensor([0.7590, 0.5606, 0.4760]).\n",
      "Average Dice over all videos is: tensor([0.7499, 0.5711, 0.5573]).\n"
     ]
    }
   ],
   "source": [
    "network_path = to_save_path\n",
    "os.makedirs(\"./pred_masks\", exist_ok=True)\n",
    "overallIoU, overallDice = doInference(network_path, config, sorted_paths, size = 384, video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df6d6ab3-1330-43db-ba3e-91c9575c5504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best .pth file Inference Completed\n"
     ]
    }
   ],
   "source": [
    "print(\"Best .pth file Inference Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed68f27",
   "metadata": {},
   "source": [
    "### Loop thorugh all best `.pth` from each run and do inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0908918-8f95-46d9-a95b-484f4c90aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "for network_path in Path(f\"./saves\").iterdir():\n",
    "    if 'checkpoint' in network_path.name or '.pth' not in network_path.name:\n",
    "        continue\n",
    "    paths.append(network_path)\n",
    "os.makedirs(\"./pred_masks\", exist_ok=True)\n",
    "\n",
    "IoUs = {}\n",
    "for network_path in sorted(paths):\n",
    "    print(network_path.name)\n",
    "    # Get testing patients from the file name eg:XMem_BinaryRLLPA_All-p1p2 -> p1, p2\n",
    "    pat_comb = network_path.name.split(\"-\")[-1]\n",
    "    p1, p2 = [match.group() for match in re.finditer(r'p(\\d{1,2})', pat_comb)]\n",
    "    print(\"Test Patients:\", p1, p2)\n",
    "    TEST_PATIENTS = set([p1, p2])\n",
    "    paths = {pat: {} for pat in TEST_PATIENTS}\n",
    "    for folder in MASKS_PATH.iterdir():\n",
    "        pat_name = folder.name.split('_')[0]\n",
    "        if pat_name not in TEST_PATIENTS:\n",
    "            continue\n",
    "        for mask_path in folder.iterdir():\n",
    "            paths[pat_name][mask_path.name] = (VIDEOS_PATH/folder.name/mask_path.name, mask_path)\n",
    "\n",
    "    sorted_paths = {pat: {k:v for k,v in sorted(l.items(), key=lambda x: x[0])} for pat, l in paths.items()}\n",
    "\n",
    "    overallIoU, overallDice = doInference(network_path, config, sorted_paths, size = 384, video=True)\n",
    "    IoUs[network_path.name] = sum(overallIoU)/len(overallIoU)\n",
    "    print('*'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa1ca4c-7448-410a-8c6a-69864c77cefc",
   "metadata": {},
   "source": [
    "### ZeroShot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e5982cc-f870-4655-a3f2-908e0f6d5a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Mask starting from: 0\n",
      "Running Inference on seq_17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:14<00:00, 16.81it/s]\n",
      "100%|██████████| 249/249 [00:08<00:00, 29.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Present Classes: Counter({0: 249, 2: 249, 3: 246, 1: 243, 4: 226, 6: 102, 8: 95, 7: 69, 11: 57, 10: 16})\n",
      "All Predicted Classes: Counter({0: 249, 2: 249, 10: 249, 3: 242, 1: 238, 4: 4, 11: 3})\n",
      "Video \"seq_17\", mean IoU is: tensor([83.3279, 58.5480, 68.0044,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  3.2336,  0.0000])\n",
      "Video \"seq_17\", mean dice is: tensor([85.7085, 69.5899, 76.3170,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  1.6262,  0.0000])\n",
      "\n",
      "Average IoU over all videos is: tensor([0.8333, 0.5855, 0.6800, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0323, 0.0000]).\n",
      "Average Dice over all videos is: tensor([0.8571, 0.6959, 0.7632, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0163, 0.0000]).\n"
     ]
    }
   ],
   "source": [
    "network_path = \"./saves/XMem.pth\"\n",
    "network_path = \"./saves/Jan23_19.31.24_Endo18All_NoAug/Jan23_19.31.24_Endo18All_NoAug_2000.pth\"\n",
    "\n",
    "TEST_PATIENTS = set([\"seq_17\"]) #set([\"seq_17\", \"seq_18\", \"seq_19\", \"seq_20\", ])\n",
    "sorted_paths = generate_paths(test_videos, test_masks, test_patients = TEST_PATIENTS)\n",
    "overallIoU, overallDice = doInference(network_path, config, sorted_paths, size = 384, video=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b146dcc-f259-44b2-a496-20a37eef47ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
